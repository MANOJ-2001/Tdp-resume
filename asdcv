Weâ€™re planning to build an AI-powered assistant tailored for our data engineering team, specifically focused on the healthcare domain. The assistant will help generate view schemas based on our internal rules and regulations â€” including PHI/API tagging, schema types (like onshore, offshore, interview), and security table mappings.

The assistant will be accessible through a chatbot interface, and we plan to build the entire solution on Azure, using Azure AI Foundry as our core platform.

ðŸ§­ Hereâ€™s the methodology we intend to follow:
1. Planning
Weâ€™ll start by defining the use case in detail and identifying the agents we need:

A Schema Agent to generate view scripts
A Compliance Agent to validate PHI/API tagging
A Workflow Agent to trigger downstream processes like Databricks or Data Factory
Weâ€™ll also gather all our internal documentation â€” rules, regulations, and schema templates â€” to serve as the knowledge base.

2. Azure Setup
Next, weâ€™ll provision the necessary Azure services:

Azure AI Foundry for orchestrating the AI workflows
Azure OpenAI for LLM capabilities
Azure AI Search for document retrieval (RAG)
Azure Blob Storage for storing internal documents
Azure Key Vault for managing secrets
Weâ€™ll also enable Managed Identities and configure RBAC to ensure secure access across services.

3. RAG Setup (Retrieval-Augmented Generation)
We plan to store our documents in Blob Storage, then index them using Azure AI Search.

The documents will be chunked and embedded into vectors.
This will allow us to retrieve relevant rules dynamically when a user asks a question.
4. Prompt Flow Design
Using Prompt Flow, weâ€™ll orchestrate the logic as follows:

An Intent Classifier will determine which agent should handle the query.
A RAG Retriever will fetch relevant rules from Azure AI Search.
The LLM Prompt will combine the user query with the retrieved context.
A Post-Processing step will format the output (e.g., SQL view script).
Each agent will be implemented as a tool or sub-flow within Prompt Flow.

5. Testing
Weâ€™ll create test cases for each agent and use Prompt Flowâ€™s built-in tools to evaluate:

The relevance of retrieved documents
The accuracy of the generated schema
Latency and performance
6. Deployment
Once tested, weâ€™ll deploy the Prompt Flow as an API endpoint.

For the frontend, weâ€™re considering options like a Web App, Power Apps, or a Teams Bot for internal access.
7. Orchestration
From within Prompt Flow, weâ€™ll trigger external workflows such as:

Databricks notebooks for data processing
Azure Data Factory pipelines for ETL
Azure SQL jobs for schema deployment
8. Governance
Weâ€™ll apply strict governance measures:

Use system prompts and content filters to restrict the model to healthcare and internal topics only
Enable logging, monitoring, and auditing using Azure Monitor and Application Insights
âœ… Expected Outcome
The result will be a secure, intelligent, and highly specialized AI assistant that empowers our developers to generate compliant view schemas quickly and accurately â€” all while staying aligned with our healthcare regulations and internal standards.
